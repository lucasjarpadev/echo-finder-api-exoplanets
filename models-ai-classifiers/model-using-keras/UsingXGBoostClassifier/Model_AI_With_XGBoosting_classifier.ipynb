{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-wZgUi-xW43"
      },
      "source": [
        "# Entrenamiento y Exportación de Modelo usando XGBoost\n",
        "Este notebook entrena un clasificador sobre KOI (cumulative), exporta artefactos ( scaler + label encoder + stats) y provee una prueba con TCEs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VRNLj73xW45",
        "outputId": "47959e81-8f6c-4887-a547-f418b9f30d0c"
      },
      "source": [
        "# Limpio si instalaste TF antes (opcional)\n",
        "!pip -q uninstall -y tensorflow tensorflow-cpu || true\n",
        "\n",
        "# Instalar lo necesario\n",
        "!pip -q install pandas numpy scikit-learn xgboost requests joblib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-cpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ5JBJ5txW45"
      },
      "source": [
        "# Imports\n",
        "import io, json, os, requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvHkVX4gxW45",
        "outputId": "308ef13b-93dd-4fb0-f7b8-819267330df5"
      },
      "source": [
        "# @title Descargar KOI cumulative (API Exoplanet Archive)\n",
        "BASE = \"https://exoplanetarchive.ipac.caltech.edu/cgi-bin/nstedAPI/nph-nstedAPI\"\n",
        "\n",
        "cols = [\n",
        " \"kepoi_name\",\"koi_disposition\",\"koi_pdisposition\",\"koi_score\",\n",
        " \"koi_period\",\"koi_duration\",\"koi_depth\",\"koi_prad\",\"koi_srad\",\n",
        " \"koi_teq\",\"koi_steff\",\"koi_slogg\",\"koi_smet\",\"koi_kepmag\",\n",
        " \"koi_model_snr\",\"koi_num_transits\"\n",
        "]\n",
        "\n",
        "where = (\"koi_disposition like 'CONFIRMED' or \"\n",
        "         \"koi_disposition like 'CANDIDATE' or \"\n",
        "         \"koi_disposition like 'FALSE POSITIVE'\")\n",
        "\n",
        "params = {\n",
        "    \"table\": \"cumulative\",\n",
        "    \"select\": \",\".join(cols),\n",
        "    \"where\": where,\n",
        "    \"format\": \"csv\"\n",
        "}\n",
        "\n",
        "r = requests.get(BASE, params=params, timeout=60)\n",
        "r.raise_for_status()\n",
        "df = pd.read_csv(io.StringIO(r.text))\n",
        "print(df.shape, df.koi_disposition.value_counts())\n",
        "df.to_csv(\"exo_full.csv\", index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9564, 16) koi_disposition\n",
            "FALSE POSITIVE    4839\n",
            "CONFIRMED         2746\n",
            "CANDIDATE         1979\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOn3cn69xW45",
        "outputId": "a4acecd0-ce49-4c61-faa8-629565704c78"
      },
      "source": [
        "# @title Split train/test y preprocesamiento\n",
        "df_tr, df_te = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"koi_disposition\"])\n",
        "df_tr = df_tr.dropna()\n",
        "df_te = df_te.dropna()\n",
        "\n",
        "feature_columns = ['koi_period', 'koi_duration', 'koi_depth', 'koi_prad',\n",
        "                   'koi_srad', 'koi_teq', 'koi_steff', 'koi_slogg',\n",
        "                   'koi_smet', 'koi_kepmag', 'koi_model_snr', 'koi_num_transits']\n",
        "\n",
        "X_tr = df_tr[feature_columns].values\n",
        "X_te = df_te[feature_columns].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_tr = label_encoder.fit_transform(df_tr['koi_disposition'])\n",
        "y_te = label_encoder.transform(df_te['koi_disposition'])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_tr = scaler.fit_transform(X_tr)\n",
        "X_te = scaler.transform(X_te)\n",
        "\n",
        "print(\"Clases:\", label_encoder.classes_)\n",
        "print(\"X_tr:\", X_tr.shape, \"y_tr:\", y_tr.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases: ['CANDIDATE' 'CONFIRMED' 'FALSE POSITIVE']\n",
            "X_tr: (6389, 12) y_tr: (6389,)\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW2MlHOgvrWD"
      },
      "source": [
        "# @title Instalamos XGBoost\n",
        "!pip -q install xgboost"
      ],
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzrzidUgvrWE"
      },
      "source": [
        "# @title Imports para XGBoost\n",
        "import numpy as np, pandas as pd, joblib, json\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF_a6pCivrWE",
        "outputId": "1d439d21-2fb2-4ef2-fe9a-87046b8d163c"
      },
      "source": [
        "# @title Entrenamos con XGBoost (multiclase)\n",
        "# Requiere: X_tr, y_tr, X_te, y_te, label_encoder ya definidos\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "xgb.fit(X_tr, y_tr)\n",
        "y_pred = xgb.predict(X_te)\n",
        "print(classification_report(y_te, y_pred, target_names=label_encoder.classes_))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "     CANDIDATE       0.60      0.60      0.60       267\n",
            "     CONFIRMED       0.84      0.85      0.84       547\n",
            "FALSE POSITIVE       0.89      0.88      0.89       785\n",
            "\n",
            "      accuracy                           0.82      1599\n",
            "     macro avg       0.78      0.78      0.78      1599\n",
            "  weighted avg       0.82      0.82      0.82      1599\n",
            "\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MgTTfEnvrWF",
        "outputId": "87a8fb1f-3678-4c0a-8816-96306e87cffb"
      },
      "source": [
        "# @title Exportamos artefactos XGBoost\n",
        "# Guarda: xgb_model.pkl, scaler.pkl, label_encoder.pkl, feature_stats.json\n",
        "import joblib, json\n",
        "\n",
        "joblib.dump(xgb, \"xgb_model.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
        "\n",
        "feature_stats = {\n",
        "    \"feature_columns\": feature_columns,\n",
        "    \"medians\": df_tr[feature_columns].median(numeric_only=True).to_dict()\n",
        "}\n",
        "with open(\"feature_stats.json\",\"w\") as f:\n",
        "    json.dump(feature_stats, f, indent=2)\n",
        "\n",
        "print(\"✅ Artefactos exportados: xgb_model.pkl, scaler.pkl, label_encoder.pkl, feature_stats.json\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Artefactos exportados: xgb_model.pkl, scaler.pkl, label_encoder.pkl, feature_stats.json\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15fee_fpxW46"
      },
      "source": [],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5hkiqYdvrWG",
        "outputId": "fb8f51de-87bc-4a47-9b1a-b69df5a03a4a"
      },
      "source": [
        "# @title (Prueba) Inferencia con XGBoost usando artefactos exportados\n",
        "# Clasifica 2 TCEs de Kepler con tu modelo XGB\n",
        "import io, requests\n",
        "\n",
        "def predict_with_artifacts(df_cases: pd.DataFrame):\n",
        "    xgb = joblib.load(\"xgb_model.pkl\")\n",
        "    sc = joblib.load(\"scaler.pkl\")\n",
        "    le = joblib.load(\"label_encoder.pkl\")\n",
        "    stats = json.load(open(\"feature_stats.json\"))\n",
        "    feature_columns = stats[\"feature_columns\"]\n",
        "    medians = stats[\"medians\"]\n",
        "    for c in feature_columns:\n",
        "        if c not in df_cases.columns:\n",
        "            df_cases[c] = np.nan\n",
        "    df_cases = df_cases[feature_columns].copy()\n",
        "    for c in feature_columns:\n",
        "        if df_cases[c].isna().any():\n",
        "            df_cases[c] = df_cases[c].fillna(medians.get(c, 0.0))\n",
        "    X = sc.transform(df_cases.values)\n",
        "    probs = xgb.predict_proba(X)\n",
        "    preds = le.inverse_transform(np.argmax(probs, axis=1))\n",
        "    return preds, probs, list(le.classes_)\n",
        "\n",
        "# Descargar 2 TCEs con mayor SNR\n",
        "TAP_URL = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
        "query = \"\"\"\n",
        "SELECT TOP 2\n",
        "  kepid, tce_plnt_num, tce_period, tce_duration, tce_depth, tce_model_snr\n",
        "FROM q1_q17_dr25_tce\n",
        "WHERE tce_period > 0 AND tce_duration > 0 AND tce_depth > 0\n",
        "ORDER BY tce_model_snr DESC\n",
        "\"\"\"\n",
        "r = requests.get(TAP_URL, params={\"query\": query, \"format\": \"csv\"}, timeout=90)\n",
        "r.raise_for_status()\n",
        "tce = pd.read_csv(io.StringIO(r.text))\n",
        "tce.columns = [c.strip().lower() for c in tce.columns]\n",
        "\n",
        "# Map mínimo TCE -> features KOI\n",
        "feature_columns = json.load(open(\"feature_stats.json\"))[\"feature_columns\"]\n",
        "cases = pd.DataFrame(index=tce.index, columns=feature_columns, dtype=\"float64\")\n",
        "mapping = {\"koi_period\":\"tce_period\",\"koi_duration\":\"tce_duration\",\"koi_depth\":\"tce_depth\",\"koi_model_snr\":\"tce_model_snr\"}\n",
        "for feat, src in mapping.items():\n",
        "    if src in tce.columns:\n",
        "        cases[feat] = pd.to_numeric(tce[src], errors=\"coerce\")\n",
        "\n",
        "preds, probs, classes = predict_with_artifacts(cases)\n",
        "print(\"Predicciones:\", preds)\n",
        "print(\"Clases:\", classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones: ['CONFIRMED' 'FALSE POSITIVE']\n",
            "Clases: ['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE']\n"
          ]
        }
      ],
      "execution_count": 9
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}